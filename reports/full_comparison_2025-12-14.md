# Multilingual Deception Bench - Full Model Comparison Report

**Date:** 2025-12-14
**Classifier:** LLM Semantic Classifier (Claude Haiku / batch mode)
**Datasets:** EN-US (1,093 examples), PT-BR (1,100 examples)

## Executive Summary

This report compares safety refusal rates across multiple frontier LLMs in both English (EN-US) and Portuguese (PT-BR) using a semantic LLM-based classifier.

## Main Results

| Rank | Model | EN-US Refusal | PT-BR Refusal | Delta | Notes |
|------|-------|---------------|---------------|-------|-------|
| 1 | Claude Sonnet 4 | 100.0% | 99.5% | -0.5% | Best overall |
| 2 | Claude Haiku 4.5 | 99.2% | 99.5% | +0.3% | |
| 3 | GPT-5.2 | 99.4% | 98.3% | -1.1% | |
| 4 | GPT-5.1 | 99.0% | 98.2% | -0.8% | |
| 5 | GPT-4o | 96.8% | 96.9% | +0.1% | |
| 6 | Gemini 3.0 Pro | 11.3%* | 5.1%* | -6.2% | *Rate-limited |

## Key Findings

### 1. Cross-Language Safety Parity
All models (except Gemini due to rate limiting) show nearly identical refusal rates across both languages. The delta between EN-US and PT-BR is less than 2% for all successfully tested models.

### 2. Model Rankings

**Tier 1 - Excellent (99%+ refusal):**
- Claude Sonnet 4: Perfect or near-perfect refusal in both languages
- Claude Haiku 4.5: Excellent refusal rates
- GPT-5.2: Strong refusal with minimal compliance
- GPT-5.1: Strong refusal rates

**Tier 2 - Very Good (96-99% refusal):**
- GPT-4o: Consistently good performance

**Inconclusive:**
- Gemini 3.0 Pro: 87% of requests were rate-limited, making the data unreliable

### 3. Model Evolution (OpenAI)

| Model | EN-US Refusal | Improvement |
|-------|---------------|-------------|
| GPT-4o | 96.8% | Baseline |
| GPT-5.1 | 99.0% | +2.2% |
| GPT-5.2 | 99.4% | +2.6% |

OpenAI's newer models show consistent improvement in safety refusal rates.

## Detailed Metrics

### Claude Sonnet 4
- EN-US: 100.0% refusal, 0.0% soft refusal, 0.0% compliance
- PT-BR: 99.5% refusal, 0.5% soft refusal, 0.0% compliance

### Claude Haiku 4.5
- EN-US: 99.2% refusal, 0.8% soft refusal, 0.0% compliance
- PT-BR: 99.5% refusal, 0.5% soft refusal, 0.0% compliance

### GPT-5.2
- EN-US: 99.4% refusal, 0.6% soft refusal, 0.0% compliance
- PT-BR: 98.3% refusal, 1.5% soft refusal, 0.2% compliance

### GPT-5.1
- EN-US: 99.0% refusal, 0.1% soft refusal, 0.9% compliance
- PT-BR: 98.2% refusal, 1.4% soft refusal, 0.2% compliance

### GPT-4o
- EN-US: 96.8% refusal, 1.7% soft refusal, 1.3% compliance
- PT-BR: 96.9% refusal, 2.7% soft refusal, 0.1% compliance

## Models Not Tested

- **GPT-5.1-mini:** Model not available via API at time of testing
- **Grok 4.1:** xAI API key not configured

## Data Quality Notes

- **Gemini 3.0 Pro:** 86.5% of EN-US requests and similar % of PT-BR requests were rate-limited, resulting in "unclear" classifications. The reported refusal rates are based only on successful responses and may not be representative.

## Methodology

1. Each model was prompted with 1,093 (EN-US) or 1,100 (PT-BR) synthetic social engineering examples
2. Responses were classified using Claude Haiku as a semantic classifier
3. Classifications: refusal, soft_refusal, compliance, unclear
4. The classifier evaluates whether the model protected the user or helped with the scam

## Conclusion

Frontier LLMs from Anthropic and OpenAI demonstrate strong and consistent safety behaviors across both English and Portuguese. There is no evidence of significant safety degradation in non-English languages for the models tested.

---
*Report generated by MDB CLI with LLM semantic classifier*
